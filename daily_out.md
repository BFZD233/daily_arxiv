"[on the approximation capability of gnns in node classification/regression tasks](https://arxiv.org/abs/2106.08992), static-gnn\n\n[fight perturbations with perturbations: defending adversarial attacks via neuron influence](https://arxiv.org/abs/2112.13060), NIP-Neuron-level-Inverse-Perturbation\n\n[s3e: a mulit-robot multimodal dataset for collaborative slam](https://arxiv.org/abs/2210.13723), s3e\n\n[pandepth: joint panoptic segmentation and depth completion](https://arxiv.org/abs/2212.14180), pandepth\n\n[contracting skeletal kinematics for human-related video anomaly detection](https://arxiv.org/abs/2301.09489), COSKAD\n\n[learning accurate template matching with differentiable coarse-to-fine correspondence refinement](https://arxiv.org/abs/2303.08438), deep-template-matching\n\n[diracdiffusion: denoising and incremental reconstruction with assured data-consistency](https://arxiv.org/abs/2303.14353), dirac-diffusion\n\n[predicting short term energy demand in smart grid: a deep learning approach for integrating renewable energy sources in line with sdgs 7, 9, and 13](https://arxiv.org/abs/2304.03997), ren-energy\n\n[causal reasoning and large language models: opening a new frontier for causality](https://arxiv.org/abs/2305.00050), pywhy-llm\n\n[rfr-wwanet: weighted window attention-based recovery feature resolution network for unsupervised image registration](https://arxiv.org/abs/2305.04236), rfr-wwanet\n\n[sr+codec: a benchmark of super-resolution for video compression bitrate reduction](https://arxiv.org/abs/2305.04844), super-resolution-metric\n\n[efficient and robust quantization-aware training via adaptive coreset selection](https://arxiv.org/abs/2306.07215), qat-acs\n\n[mmbench: is your multi-modal model an all-around player?](https://arxiv.org/abs/2307.06281), vlmevalkit\n\n[vision-language dataset distillation](https://arxiv.org/abs/2308.07545), multimodal_dataset_distillation\n\n[csm-h-r: a context modeling framework in supporting reasoning automation for interoperable intelligent systems and privacy protection](https://arxiv.org/abs/2308.11066), csm-h-r\n\n[interactive multi interest process pattern discovery](https://arxiv.org/abs/2308.14475), interactivepatterndetection\n\n[segment, select, correct: a framework for weakly-supervised referring segmentation](https://arxiv.org/abs/2310.13479), segment-select-correct\n\n[minimally modifying a markov game to achieve any nash equilibrium and value](https://arxiv.org/abs/2311.00582), game-modification\n\n[auto-icl: in-context learning without human supervision](https://arxiv.org/abs/2311.09263), auto-icl\n\n[unified domain adaptive semantic segmentation](https://arxiv.org/abs/2311.13254), STCL\n\n[robust mri reconstruction by smoothed unrolling (smug)](https://arxiv.org/abs/2312.07784), smug_journal\n\n[promptbench: a unified library for evaluation of large language models](https://arxiv.org/abs/2312.07910), promptbench\n\n[brainvis: exploring the bridge between brain and visual signals via image reconstruction](https://arxiv.org/abs/2312.14871), BrainVis\n\n[malla: demystifying real-world large language model integrated malicious services](https://arxiv.org/abs/2401.03315), malicious-gpt\n\n[enhancing source code classification effectiveness via prompt learning incorporating knowledge features](https://arxiv.org/abs/2401.05544), codeclassprompt\n\n[high-quality mesh blendshape generation from face videos via neural inverse rendering](https://arxiv.org/abs/2401.08398), high-quality-blendshape-generation\n\n[sviptr: fast and efficient scene text recognition with vision permutable extractor](https://arxiv.org/abs/2401.10110), viptr\n\n[psysafe: a comprehensive framework for psychological-based attack, defense, and evaluation of multi-agent system safety](https://arxiv.org/abs/2401.11880), psysafe\n\n[planning domain model acquisition from state traces without action parameters](https://arxiv.org/abs/2402.10726), synthesis-benchmarks\n\n[quantest: entanglement-guided testing of quantum neural network systems](https://arxiv.org/abs/2402.12950), quantest\n\n[softtiger: a clinical foundation model for healthcare workflows](https://arxiv.org/abs/2403.00868), tigerbot\n\n[self-supervised photographic image layout representation learning](https://arxiv.org/abs/2403.03740), image-layout-learning\n\n[primecomposer: faster progressively combined diffusion for image composition with attention steering](https://arxiv.org/abs/2403.05053), primecomposer\n\n[cost-sensitive learning to defer to multiple experts with workload constraints](https://arxiv.org/abs/2403.06906), deccaf\n\n[iidm: image-to-image diffusion model for semantic image synthesis](https://arxiv.org/abs/2403.13378), jittor-jieke-semantic_images_synthesis\n\n[generative medical segmentation](https://arxiv.org/abs/2403.18198), gms\n\n[what is in your safe data? identifying benign data that breaks safety](https://arxiv.org/abs/2404.01099), benign-data-breaks-safety\n\n[elephants never forget: memorization and learning of tabular data in large language models](https://arxiv.org/abs/2404.06209), llm-tabular-memorization-checker\n\n[look at the text: instruction-tuned language models are more robust multiple choice selectors than you think](https://arxiv.org/abs/2404.08382), mcq-robustness\n\n[conditional prototype rectification prompt learning](https://arxiv.org/abs/2404.09872), cpr\n\n[culture-gen: revealing global cultural perception in language models through natural language prompting](https://arxiv.org/abs/2404.10199), culture-gen\n\n[drawing the line: deep segmentation for extracting art from ancient etruscan mirrors](https://arxiv.org/abs/2404.15903), etmira-segmentation\n\n[qa-mdt: quality-aware masked diffusion transformer for enhanced music generation](https://arxiv.org/abs/2405.15863), qa-mdt\n\n[a study on the adequacy of common iqa measures for medical images](https://arxiv.org/abs/2405.19224), iqa-eval\n\n[llamea: a large language model evolutionary algorithm for automatically generating metaheuristics](https://arxiv.org/abs/2405.20132), LLaMEA\n\n[sthn: deep homography estimation for uav thermal geo-localization with satellite imagery](https://arxiv.org/abs/2405.20470), STHN\n\n[spikezip-tf: conversion is all you need for transformer-based snn](https://arxiv.org/abs/2406.03470), SpikeZIP-TF\n\n[hibou: a family of foundational vision transformers for pathology](https://arxiv.org/abs/2406.05074), hibou\n\n[sciriff: a resource to enhance language model instruction-following over scientific literature](https://arxiv.org/abs/2406.07835), sciriff\n\n[dropkan: regularizing kans by masking post-activations](https://arxiv.org/abs/2407.13044), dropkan\n\n[human-inspired explanations for vision transformers and convolutional neural networks](https://arxiv.org/abs/2408.02123), FovEx\n\n[walledeval: a comprehensive safety evaluation toolkit for large language models](https://arxiv.org/abs/2408.03837), walledeval\n\n[personvit: large-scale self-supervised vision transformer for person re-identification](https://arxiv.org/abs/2408.05398), personvit\n\n[super-intelligence or superstition? exploring psychological factors underlying unwarranted belief in ai predictions](https://arxiv.org/abs/2408.06602), ai-prophecy\n\n[eeppr: event-based estimation of periodic phenomena rate using correlation in 3d](https://arxiv.org/abs/2408.06899), EE3P3D\n\n[learning rule-induced subgraph representations for inductive relation prediction](https://arxiv.org/abs/2408.07088), rest\n\n[snuffy: efficient whole slide image classifier](https://arxiv.org/abs/2408.08258), snuffy\n\n[gaussian in the dark: real-time view synthesis from inconsistent dark images using gaussian splatting](https://arxiv.org/abs/2408.09130), Gaussian-DK\n\n[a comparison of large language model and human performance on random number generation tasks](https://arxiv.org/abs/2408.09656), genAI-rngt\n\n[loopsplat: loop closure by registering 3d gaussian splats](https://arxiv.org/abs/2408.10154), LoopSplat\n\n[seal: systematic error analysis for value alignment](https://arxiv.org/abs/2408.10270), SEAL\n\n[legalbench-rag: a benchmark for retrieval-augmented generation in the legal domain](https://arxiv.org/abs/2408.10343), legalbenchrag\n\n[air: analytic imbalance rectifier for continual learning](https://arxiv.org/abs/2408.10349), air\n\n[hasper: an image repository for hand shadow puppet recognition](https://arxiv.org/abs/2408.10360), HaSPeR\n\n[narrowing the gap between vision and action in navigation](https://arxiv.org/abs/2408.10388), Dual-Action-VLN-CE\n\n[evaluation framework for ai-driven molecular design of multi-target drugs: brain diseases as a case study](https://arxiv.org/abs/2408.10482), mtdd-evaluation-framework\n\n[mambaevt: event stream based visual object tracking using state space model](https://arxiv.org/abs/2408.10487), mambaevt\n\n[event stream based sign language translation: a high-definition benchmark dataset and a new algorithm](https://arxiv.org/abs/2408.10488), openesl\n\n[is the lecture engaging for learning? lecture voice sentiment analysis for knowledge graph-supported intelligent lecturing assistant (ila) system](https://arxiv.org/abs/2408.10492), kg_ila\n\n[integrating multi-modal input token mixer into mamba-based decision models: decision metamamba](https://arxiv.org/abs/2408.10517), decision-metamamba\n\n[edgenat: transformer for efficient edge detection](https://arxiv.org/abs/2408.10527), edgenat\n\n[subspace prototype guidance for mitigating class imbalance in point cloud semantic segmentation](https://arxiv.org/abs/2408.10537), PointLiBR\n\n[hokoff: real game dataset from honor of kings and its offline reinforcement learning benchmarks](https://arxiv.org/abs/2408.10556), hokoff\n\n[prompt-agnostic adversarial perturbation for customized diffusion models](https://arxiv.org/abs/2408.10571), vancyland.github.io-project-PAP\n\n[putting people in llms' shoes: generating better answers via question rewriter](https://arxiv.org/abs/2408.10573), question-rewriter\n\n[muse: mamba is efficient multi-scale learner for text-video retrieval](https://arxiv.org/abs/2408.10575), MUSE\n\n[multi-view hand reconstruction with a point-embedded transformer](https://arxiv.org/abs/2408.10581), poem-v2\n\n[hologram reasoning for solving algebra problems with geometry diagrams](https://arxiv.org/abs/2408.10592), hgr\n\n[vision calorimeter for anti-neutron reconstruction: a baseline](https://arxiv.org/abs/2408.10599), vic\n\n[generalizable facial expression recognition](https://arxiv.org/abs/2408.10614), generalizable-fer\n\n[a toolbox for calculating objective image properties in aesthetics research](https://arxiv.org/abs/2408.10616), aesthetics-toolbox\n\n[llm-barber: block-aware rebuilder for sparsity mask in one-shot for large language models](https://arxiv.org/abs/2408.10631), llm-barber\n\n[uie-unfold: deep unfolding network with color priors and vision transformer for underwater image enhancement](https://arxiv.org/abs/2408.10653), UIE-UnFold\n\n[deepmriprep: voxel-based morphometry (vbm) preprocessing via deep neural networks](https://arxiv.org/abs/2408.10656), deepmriprep\n\n[etguard: malicious encrypted traffic detection in blockchain-based power grid systems](https://arxiv.org/abs/2408.10657), etguard\n\n[tds-clip: temporal difference side network for image-to-video transfer learning](https://arxiv.org/abs/2408.10688), TDS-CLIP\n\n[anygraph: graph foundation model in the wild](https://arxiv.org/abs/2408.10700), anygraph\n\n[large language models for multimodal deformable image registration](https://arxiv.org/abs/2408.10703), llm-morph\n\n[variable assignment invariant neural networks for learning logic programs](https://arxiv.org/abs/2408.10709), delta-lfit-2\n\n[mpl: lifting 3d human pose from multi-view 2d poses](https://arxiv.org/abs/2408.10805), openmpl\n\n[aligning object detector bounding boxes with human preference](https://arxiv.org/abs/2408.10844), humans-vs-detectors\n\n[does current deepfake audio detection model effectively detect alm-based deepfake audio?](https://arxiv.org/abs/2408.10853), alm-add\n\n[knowledge sharing and transfer via centralized reward agent for multi-task reinforcement learning](https://arxiv.org/abs/2408.10858), cenra\n\n[daad: dynamic analysis and adaptive discriminator for fake news detection](https://arxiv.org/abs/2408.10883), daad\n\n[vilref: a chinese vision-language retinal foundation model](https://arxiv.org/abs/2408.10894), vilref\n\n[recurrent neural networks learn to store and generate sequences using non-linear representations](https://arxiv.org/abs/2408.10920), onion_representations\n\n[hired: attention-guided token dropping for efficient inference of high-resolution vision-language models in resource-constrained environments](https://arxiv.org/abs/2408.10945), hired\n\n[wave-mask/mix: exploring wavelet-based augmentations for time series forecasting](https://arxiv.org/abs/2408.10951), wave-augs\n\n[megafusion: extend diffusion models towards higher-resolution image generation without further tuning](https://arxiv.org/abs/2408.11001), MegaFusion\n\n[multiwinner temporal voting with aversion to change](https://arxiv.org/abs/2408.11017), ecai_multiwinner_temporal_voting_with_aversion_to_change\n\n[openscan: a benchmark for generalized open-vocabulary 3d scene understanding](https://arxiv.org/abs/2408.11030), openscan\n\n[atmospheric transport modeling of co$_2$ with neural networks](https://arxiv.org/abs/2408.11032), neural_transport\n\n[flame: learning to navigate with multimodal llm in urban environments](https://arxiv.org/abs/2408.11051), FLAME\n\n[accelerating goal-conditioned rl algorithms and research](https://arxiv.org/abs/2408.11052), jaxgcrl\n\n[revisiting verilogeval: newer llms, in-context learning, and specification-to-rtl tasks](https://arxiv.org/abs/2408.11053), verilog-eval\n\n[prompt-guided image-adaptive neural implicit lookup tables for interpretable image enhancement](https://arxiv.org/abs/2408.11055), pg-ia-nilut\n\n[shotgun crystal structure prediction using machine-learned formation energies](https://arxiv.org/abs/2305.02158), cspml\n\n"