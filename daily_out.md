"[Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of\n  Encoders](http://arxiv.org/abs/2408.15998v1), eagle\n\n[CoGen: Learning from Feedback with Coupled Comprehension and Generation](http://arxiv.org/abs/2408.15992v1), cogen\n\n[Distribution Backtracking Builds A Faster Convergence Trajectory for\n  One-step Diffusion Distillation](http://arxiv.org/abs/2408.15991v1), disback\n\n[InstanSeg: an embedding-based instance segmentation algorithm optimized\n  for accurate, efficient and portable cell segmentation](http://arxiv.org/abs/2408.15954v1), instanseg\n\n[Network transferability of adversarial patches in real-time object\n  detection](http://arxiv.org/abs/2408.15833v1), transferability\n\n[SITransformer: Shared Information-Guided Transformer for Extreme\n  Multimodal Summarization](http://arxiv.org/abs/2408.15829v1), mmasia24-xmsmo\n\n[Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation](http://arxiv.org/abs/2408.15810v1), human3.6m-occluded\n\n[A Survey on Facial Expression Recognition of Static and Dynamic Emotions](http://arxiv.org/abs/2408.15777v1), surveyfer\n\n[DEAR: Depth-Enhanced Action Recognition](http://arxiv.org/abs/2408.15679v1), dear\n\n[Merging and Splitting Diffusion Paths for Semantically Coherent\n  Panoramas](http://arxiv.org/abs/2408.15660v1), mad\n\n[TeFF: Tracking-enhanced Forgetting-free Few-shot 3D LiDAR Semantic\n  Segmentation](http://arxiv.org/abs/2408.15657v1), track-no-forgetting\n\n[\u03bcgat: Improving Single-Page Document Parsing by Providing Multi-Page\n  Context](http://arxiv.org/abs/2408.15646v1), mugat\n\n[MMDRFuse: Distilled Mini-Model with Dynamic Refresh for Multi-Modality\n  Image Fusion](http://arxiv.org/abs/2408.15641v1), mmdrfuse\n\n[CSAD: Unsupervised Component Segmentation for Logical Anomaly Detection](http://arxiv.org/abs/2408.15628v1), CSAD\n\n[On the Benefits of Visual Stabilization for Frame- and Event-based\n  Perception](http://arxiv.org/abs/2408.15602v1), visual_stabilization\n\n[Mamba or Transformer for Time Series Forecasting? Mixture of Universals\n  (MoU) Is All You Need](http://arxiv.org/abs/2408.15997v1), mou\n\n[Emulating Brain-like Rapid Learning in Neuromorphic Edge Computing](http://arxiv.org/abs/2408.15800v1), snn_maml\n\n[Evaluating Named Entity Recognition Using Few-Shot Prompting with Large\n  Language Models](http://arxiv.org/abs/2408.15796v1), ner-llm\n\n[Hierarchical Blockmodelling for Knowledge Graphs](http://arxiv.org/abs/2408.15649v1), hb\n\n[CBF-LLM: Safe Control for LLM Alignment](http://arxiv.org/abs/2408.15625v1), cbf-llm\n\n[TrafficGamer: Reliable and Flexible Traffic Simulation for\n  Safety-Critical Scenarios with Game-Theoretic Oracles](http://arxiv.org/abs/2408.15538v1), TrafficGamer\n\n[Towards Fully Autonomous Research Powered by LLMs: Case Study on\n  Simulations](http://arxiv.org/abs/2408.15512v1), autonomous_simulation_agent\n\n[chemtrain: Learning Deep Potential Models via Automatic Differentiation\n  and Statistical Physics](http://arxiv.org/abs/2408.15852v1), chemtrain\n\n"